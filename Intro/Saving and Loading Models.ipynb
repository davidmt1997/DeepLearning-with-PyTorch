{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Models\n",
    "\n",
    "In this notebook, I'll show you how to save and load models with PyTorch. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 231,
       "width": 231
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a network\n",
    "\n",
    "To make things more concise here, I moved the model architecture and training code from the last part to a file called fc_model. Importing this, we can easily create a fully-connected network with fc_model.Network, and train the network using fc_model.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network, define the criterion and optimizer\n",
    "\n",
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.746..  Test Loss: 1.002..  Test Accuracy: 0.616\n",
      "Epoch: 1/2..  Training Loss: 1.012..  Test Loss: 0.736..  Test Accuracy: 0.728\n",
      "Epoch: 1/2..  Training Loss: 0.858..  Test Loss: 0.684..  Test Accuracy: 0.740\n",
      "Epoch: 1/2..  Training Loss: 0.834..  Test Loss: 0.651..  Test Accuracy: 0.751\n",
      "Epoch: 1/2..  Training Loss: 0.743..  Test Loss: 0.617..  Test Accuracy: 0.761\n",
      "Epoch: 1/2..  Training Loss: 0.702..  Test Loss: 0.596..  Test Accuracy: 0.779\n",
      "Epoch: 1/2..  Training Loss: 0.699..  Test Loss: 0.583..  Test Accuracy: 0.785\n",
      "Epoch: 1/2..  Training Loss: 0.689..  Test Loss: 0.588..  Test Accuracy: 0.778\n",
      "Epoch: 1/2..  Training Loss: 0.666..  Test Loss: 0.553..  Test Accuracy: 0.795\n",
      "Epoch: 1/2..  Training Loss: 0.685..  Test Loss: 0.555..  Test Accuracy: 0.796\n",
      "Epoch: 1/2..  Training Loss: 0.584..  Test Loss: 0.538..  Test Accuracy: 0.803\n",
      "Epoch: 1/2..  Training Loss: 0.613..  Test Loss: 0.529..  Test Accuracy: 0.806\n",
      "Epoch: 1/2..  Training Loss: 0.602..  Test Loss: 0.517..  Test Accuracy: 0.809\n",
      "Epoch: 1/2..  Training Loss: 0.573..  Test Loss: 0.515..  Test Accuracy: 0.811\n",
      "Epoch: 1/2..  Training Loss: 0.565..  Test Loss: 0.510..  Test Accuracy: 0.812\n",
      "Epoch: 1/2..  Training Loss: 0.617..  Test Loss: 0.510..  Test Accuracy: 0.815\n",
      "Epoch: 1/2..  Training Loss: 0.591..  Test Loss: 0.491..  Test Accuracy: 0.820\n",
      "Epoch: 1/2..  Training Loss: 0.574..  Test Loss: 0.502..  Test Accuracy: 0.819\n",
      "Epoch: 1/2..  Training Loss: 0.577..  Test Loss: 0.493..  Test Accuracy: 0.818\n",
      "Epoch: 1/2..  Training Loss: 0.582..  Test Loss: 0.518..  Test Accuracy: 0.812\n",
      "Epoch: 1/2..  Training Loss: 0.582..  Test Loss: 0.495..  Test Accuracy: 0.814\n",
      "Epoch: 1/2..  Training Loss: 0.581..  Test Loss: 0.490..  Test Accuracy: 0.824\n",
      "Epoch: 1/2..  Training Loss: 0.586..  Test Loss: 0.496..  Test Accuracy: 0.817\n",
      "Epoch: 2/2..  Training Loss: 0.555..  Test Loss: 0.478..  Test Accuracy: 0.826\n",
      "Epoch: 2/2..  Training Loss: 0.546..  Test Loss: 0.464..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.525..  Test Loss: 0.469..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.523..  Test Loss: 0.471..  Test Accuracy: 0.831\n",
      "Epoch: 2/2..  Training Loss: 0.528..  Test Loss: 0.466..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.526..  Test Loss: 0.483..  Test Accuracy: 0.822\n",
      "Epoch: 2/2..  Training Loss: 0.558..  Test Loss: 0.477..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.578..  Test Loss: 0.462..  Test Accuracy: 0.831\n",
      "Epoch: 2/2..  Training Loss: 0.475..  Test Loss: 0.463..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.541..  Test Loss: 0.453..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.526..  Test Loss: 0.452..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.526..  Test Loss: 0.442..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 0.543..  Test Loss: 0.474..  Test Accuracy: 0.825\n",
      "Epoch: 2/2..  Training Loss: 0.511..  Test Loss: 0.454..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.517..  Test Loss: 0.464..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.503..  Test Loss: 0.451..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.533..  Test Loss: 0.438..  Test Accuracy: 0.839\n",
      "Epoch: 2/2..  Training Loss: 0.541..  Test Loss: 0.451..  Test Accuracy: 0.842\n",
      "Epoch: 2/2..  Training Loss: 0.501..  Test Loss: 0.458..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.540..  Test Loss: 0.444..  Test Accuracy: 0.838\n",
      "Epoch: 2/2..  Training Loss: 0.528..  Test Loss: 0.449..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.492..  Test Loss: 0.441..  Test Accuracy: 0.846\n",
      "Epoch: 2/2..  Training Loss: 0.524..  Test Loss: 0.456..  Test Accuracy: 0.836\n"
     ]
    }
   ],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading data\n",
    "\n",
    "It's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n",
    "\n",
    "The parameters for PyTorch networks are stored in a model's state_dict. We can see the state dict contains the weight and bias matrices for each of our layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model to a file\n",
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "# loading the model again\n",
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and load the state dict into the network\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c8002ed3459f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."
     ]
    }
   ],
   "source": [
    "# Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture. \n",
    "# If I create a model with a different architecture, this fails.\n",
    "# Try this\n",
    "model = fc_model.Network(784, 10, [400, 200, 100])\n",
    "# This will throw an error because the tensor sizes are wrong!\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means we need to rebuild the model exactly as it was when trained.\n",
    "# To do this, you build a dictionary with all the information you need to compeletely rebuild the model.\n",
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Similarly, we can write a function to load checkpoints. \n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
