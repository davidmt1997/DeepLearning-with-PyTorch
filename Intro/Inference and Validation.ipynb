{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use our neural network to make predictions (inference)\n",
    "\n",
    "To avoid overfitting, we will use a validation set to test the performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model as usual\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of validation is to measure the model's performance on data that isn't part of the training set. \n",
    "\n",
    "Performance here is up to the developer to define though. Typically this is just accuracy, the percentage of classes the network predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "# Get the class probabilities\n",
    "ps = torch.exp(model(images))\n",
    "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the probabilities, we can get the most likely class using the ps.topk method. This returns the ùëò highest values. Since we just want the most likely class, we can use ps.topk(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [1],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "# Look at the most likely classes for the first 10 examples\n",
    "print(top_class[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check if the predicted classes match the labels\n",
    "\n",
    "We have to be careful of the shapes. Here top_class is a 2D tensor with shape (64, 1) while labels is 1D with shape (64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equals will have shape (64, 64)\n",
    "# It is comparing the one element in each row of top_class with each element in labels \n",
    "# returns 64 True/False boolean values for each row.\n",
    "equals = top_class == labels.view(*top_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 7.8125%\n"
     ]
    }
   ],
   "source": [
    "# calculating the percentage of correct predictions\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30..  Training Loss: 0.517..  Test Loss: 0.461..  Test Accuracy: 0.822\n",
      "Accuracy: 12903.125%\n",
      "Epoch: 2/30..  Training Loss: 0.391..  Test Loss: 0.411..  Test Accuracy: 0.848\n",
      "Accuracy: 13315.625%\n",
      "Epoch: 3/30..  Training Loss: 0.356..  Test Loss: 0.399..  Test Accuracy: 0.854\n",
      "Accuracy: 13400.0%\n",
      "Epoch: 4/30..  Training Loss: 0.332..  Test Loss: 0.421..  Test Accuracy: 0.857\n",
      "Accuracy: 13448.4375%\n",
      "Epoch: 5/30..  Training Loss: 0.317..  Test Loss: 0.379..  Test Accuracy: 0.867\n",
      "Accuracy: 13617.1875%\n",
      "Epoch: 6/30..  Training Loss: 0.301..  Test Loss: 0.371..  Test Accuracy: 0.868\n",
      "Accuracy: 13625.0%\n",
      "Epoch: 7/30..  Training Loss: 0.288..  Test Loss: 0.390..  Test Accuracy: 0.865\n",
      "Accuracy: 13579.6875%\n",
      "Epoch: 8/30..  Training Loss: 0.281..  Test Loss: 0.355..  Test Accuracy: 0.879\n",
      "Accuracy: 13800.0%\n",
      "Epoch: 9/30..  Training Loss: 0.272..  Test Loss: 0.362..  Test Accuracy: 0.875\n",
      "Accuracy: 13734.375%\n",
      "Epoch: 10/30..  Training Loss: 0.266..  Test Loss: 0.341..  Test Accuracy: 0.880\n",
      "Accuracy: 13821.875%\n",
      "Epoch: 11/30..  Training Loss: 0.257..  Test Loss: 0.370..  Test Accuracy: 0.878\n",
      "Accuracy: 13789.0625%\n",
      "Epoch: 12/30..  Training Loss: 0.251..  Test Loss: 0.358..  Test Accuracy: 0.880\n",
      "Accuracy: 13818.75%\n",
      "Epoch: 13/30..  Training Loss: 0.245..  Test Loss: 0.414..  Test Accuracy: 0.863\n",
      "Accuracy: 13553.125%\n",
      "Epoch: 14/30..  Training Loss: 0.241..  Test Loss: 0.363..  Test Accuracy: 0.879\n",
      "Accuracy: 13801.5625%\n",
      "Epoch: 15/30..  Training Loss: 0.236..  Test Loss: 0.388..  Test Accuracy: 0.870\n",
      "Accuracy: 13665.625%\n",
      "Epoch: 16/30..  Training Loss: 0.229..  Test Loss: 0.363..  Test Accuracy: 0.882\n",
      "Accuracy: 13846.875%\n",
      "Epoch: 17/30..  Training Loss: 0.225..  Test Loss: 0.380..  Test Accuracy: 0.883\n",
      "Accuracy: 13862.5%\n",
      "Epoch: 18/30..  Training Loss: 0.219..  Test Loss: 0.403..  Test Accuracy: 0.877\n",
      "Accuracy: 13773.4375%\n",
      "Epoch: 19/30..  Training Loss: 0.214..  Test Loss: 0.378..  Test Accuracy: 0.884\n",
      "Accuracy: 13885.9375%\n",
      "Epoch: 20/30..  Training Loss: 0.215..  Test Loss: 0.384..  Test Accuracy: 0.881\n",
      "Accuracy: 13835.9375%\n",
      "Epoch: 21/30..  Training Loss: 0.206..  Test Loss: 0.425..  Test Accuracy: 0.873\n",
      "Accuracy: 13698.4375%\n",
      "Epoch: 22/30..  Training Loss: 0.206..  Test Loss: 0.384..  Test Accuracy: 0.883\n",
      "Accuracy: 13867.1875%\n",
      "Epoch: 23/30..  Training Loss: 0.201..  Test Loss: 0.433..  Test Accuracy: 0.876\n",
      "Accuracy: 13750.0%\n",
      "Epoch: 24/30..  Training Loss: 0.202..  Test Loss: 0.424..  Test Accuracy: 0.880\n",
      "Accuracy: 13817.1875%\n",
      "Epoch: 25/30..  Training Loss: 0.196..  Test Loss: 0.427..  Test Accuracy: 0.878\n",
      "Accuracy: 13778.125%\n",
      "Epoch: 26/30..  Training Loss: 0.194..  Test Loss: 0.418..  Test Accuracy: 0.881\n",
      "Accuracy: 13834.375%\n",
      "Epoch: 27/30..  Training Loss: 0.191..  Test Loss: 0.426..  Test Accuracy: 0.878\n",
      "Accuracy: 13781.25%\n",
      "Epoch: 28/30..  Training Loss: 0.185..  Test Loss: 0.434..  Test Accuracy: 0.883\n",
      "Accuracy: 13870.3125%\n",
      "Epoch: 29/30..  Training Loss: 0.187..  Test Loss: 0.470..  Test Accuracy: 0.875\n",
      "Accuracy: 13735.9375%\n",
      "Epoch: 30/30..  Training Loss: 0.185..  Test Loss: 0.412..  Test Accuracy: 0.883\n",
      "Accuracy: 13865.625%\n"
     ]
    }
   ],
   "source": [
    "# Implementing validation and printing out accuracy in each loop\n",
    "\n",
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks tend to overfit because they become too familiar with the training data and they hace problems generalizing.\n",
    "\n",
    "The most common method to reduce overfitting (outside of early-stopping) is dropout, where we randomly drop input units. This forces the network to share information between weights, increasing it's ability to generalize to new data. Adding dropout in PyTorch is straightforward using the nn.Dropout module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dropout to our model\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30..  Training Loss: 0.604..  Test Loss: 0.470..  Test Accuracy: 0.832\n",
      "Epoch: 2/30..  Training Loss: 0.484..  Test Loss: 0.452..  Test Accuracy: 0.843\n",
      "Epoch: 3/30..  Training Loss: 0.455..  Test Loss: 0.407..  Test Accuracy: 0.856\n",
      "Epoch: 4/30..  Training Loss: 0.435..  Test Loss: 0.400..  Test Accuracy: 0.855\n",
      "Epoch: 5/30..  Training Loss: 0.418..  Test Loss: 0.415..  Test Accuracy: 0.851\n",
      "Epoch: 6/30..  Training Loss: 0.410..  Test Loss: 0.380..  Test Accuracy: 0.865\n",
      "Epoch: 7/30..  Training Loss: 0.403..  Test Loss: 0.411..  Test Accuracy: 0.862\n",
      "Epoch: 8/30..  Training Loss: 0.396..  Test Loss: 0.390..  Test Accuracy: 0.865\n",
      "Epoch: 9/30..  Training Loss: 0.396..  Test Loss: 0.406..  Test Accuracy: 0.857\n",
      "Epoch: 10/30..  Training Loss: 0.391..  Test Loss: 0.371..  Test Accuracy: 0.866\n",
      "Epoch: 11/30..  Training Loss: 0.381..  Test Loss: 0.386..  Test Accuracy: 0.871\n",
      "Epoch: 12/30..  Training Loss: 0.379..  Test Loss: 0.393..  Test Accuracy: 0.862\n",
      "Epoch: 13/30..  Training Loss: 0.379..  Test Loss: 0.376..  Test Accuracy: 0.863\n",
      "Epoch: 14/30..  Training Loss: 0.374..  Test Loss: 0.380..  Test Accuracy: 0.863\n",
      "Epoch: 15/30..  Training Loss: 0.375..  Test Loss: 0.371..  Test Accuracy: 0.873\n",
      "Epoch: 16/30..  Training Loss: 0.362..  Test Loss: 0.399..  Test Accuracy: 0.866\n",
      "Epoch: 17/30..  Training Loss: 0.363..  Test Loss: 0.399..  Test Accuracy: 0.865\n",
      "Epoch: 18/30..  Training Loss: 0.355..  Test Loss: 0.386..  Test Accuracy: 0.867\n",
      "Epoch: 19/30..  Training Loss: 0.361..  Test Loss: 0.381..  Test Accuracy: 0.868\n",
      "Epoch: 20/30..  Training Loss: 0.358..  Test Loss: 0.381..  Test Accuracy: 0.866\n",
      "Epoch: 21/30..  Training Loss: 0.369..  Test Loss: 0.371..  Test Accuracy: 0.876\n",
      "Epoch: 22/30..  Training Loss: 0.355..  Test Loss: 0.376..  Test Accuracy: 0.871\n",
      "Epoch: 23/30..  Training Loss: 0.357..  Test Loss: 0.370..  Test Accuracy: 0.873\n",
      "Epoch: 24/30..  Training Loss: 0.354..  Test Loss: 0.362..  Test Accuracy: 0.876\n",
      "Epoch: 25/30..  Training Loss: 0.348..  Test Loss: 0.373..  Test Accuracy: 0.872\n",
      "Epoch: 26/30..  Training Loss: 0.344..  Test Loss: 0.361..  Test Accuracy: 0.872\n",
      "Epoch: 27/30..  Training Loss: 0.350..  Test Loss: 0.379..  Test Accuracy: 0.872\n",
      "Epoch: 28/30..  Training Loss: 0.348..  Test Loss: 0.367..  Test Accuracy: 0.871\n",
      "Epoch: 29/30..  Training Loss: 0.346..  Test Loss: 0.363..  Test Accuracy: 0.876\n",
      "Epoch: 30/30..  Training Loss: 0.343..  Test Loss: 0.411..  Test Accuracy: 0.861\n"
     ]
    }
   ],
   "source": [
    "# Training and see if we can get better accuracy\n",
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can use it for inference. We need to remember to set the model in inference mode with model.eval(). You'll also want to turn off autograd with the torch.no_grad() context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import helper module (should be in the repo)\n",
    "import helper\n",
    "\n",
    "# Test out your network!\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
